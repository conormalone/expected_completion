{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist #function to create adjacency matrix\n",
    "import math\n",
    "import tensorflow\n",
    "import spektral\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from spektral.data import Dataset, BatchLoader, Graph, DisjointLoader\n",
    "from spektral.transforms.normalize_adj import NormalizeAdj\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from spektral.layers import GCNConv, GlobalSumPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = pd.read_csv(\"data/pass_receiver.csv\")\n",
    "pff = pd.read_csv(\"data/pffScoutingData.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in weekly tracking files and concatenate into one tracking file, then delete weeklies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1 = pd.read_csv(\"data/week1.csv\")\n",
    "week2 = pd.read_csv(\"data/week2.csv\")\n",
    "week3 = pd.read_csv(\"data/week3.csv\")\n",
    "week4 = pd.read_csv(\"data/week4.csv\")\n",
    "week5 = pd.read_csv(\"data/week5.csv\")\n",
    "week6 = pd.read_csv(\"data/week6.csv\")\n",
    "week7 = pd.read_csv(\"data/week7.csv\")\n",
    "week8 = pd.read_csv(\"data/week8.csv\")\n",
    "tracking = pd.concat([week1,week2,week3,week4,week5,week6,week7,week8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save memory\n",
    "del week1,week2,week3,week4,week5,week6,week7,week8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gameId', 'playId', 'nflId', 'frameId', 'time', 'jerseyNumber', 'team',\n",
       "       'playDirection', 'x', 'y', 's', 'a', 'dis', 'o', 'dir', 'event'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add unique identifier of each play and frame (some playIds repeat over games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking[\"comb_id\"] = tracking[\"gameId\"].astype(\"str\")+\" \"+tracking[\"playId\"].astype(\"str\")\n",
    "pff[\"comb_id\"] = pff[\"gameId\"].astype(\"str\")+\" \"+pff[\"playId\"].astype(\"str\")\n",
    "plays[\"comb_id\"] = plays[\"gameId\"].astype(\"str\")+\" \"+plays[\"playId\"].astype(\"str\")\n",
    "tracking[\"comb_and_frame\"] = tracking[\"gameId\"].astype(\"str\")+\" \"+tracking[\"playId\"].astype(\"str\")+\" \"+tracking[\"frameId\"].astype(\"str\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isolate frames at time of pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate just forward passes and leave out a certain frame (duplicate forward pass for a play)\n",
    "just_forward_passes = tracking[(tracking[\"event\"]==\"pass_forward\") & (tracking[\"comb_and_frame\"]!=\"2021091203 3740 32\")& (tracking[\"team\"]!=\"football\")]\n",
    "#bring in receiver info from plays\n",
    "tracking_plays =just_forward_passes.merge(plays[[\"comb_id\",\"possessionTeam\",\"is_pass_failed\",\"PassReceiver_nflId\"]], how=\"left\",on=\"comb_id\" )\n",
    "#and qb info from pff\n",
    "tracking_merged_all = tracking_plays.merge(pff[[\"comb_id\",\"nflId\",\"pff_role\"]], how = \"left\",on=[\"comb_id\",\"nflId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166034"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(just_forward_passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166276"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tracking_plays)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isolate tracking to just QB, OL, receiver and defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_players_filtered = tracking_merged_all[(tracking_merged_all[\"nflId\"]==tracking_merged_all[\"PassReceiver_nflId\"])|(tracking_merged_all[\"pff_role\"]==\"Pass\")|(tracking_merged_all[\"pff_role\"]==\"Pass Block\")|(tracking_merged_all[\"team\"]!=tracking_merged_all[\"possessionTeam\"])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to take in 1 pass play and put it in graph format( list containing adjacency matrix, features, y) this will then be parallelized for all passes in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = tracking_players_filtered[tracking_players_filtered.comb_id == \"2021090900 97\"]\n",
    "#data_dist = data[[\"x\",\"y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_relative_diff(a,b):\n",
    "    diff_list = []\n",
    "    for i in range(len(a)):\n",
    "        difference = a[i] - b[0]\n",
    "        if difference < -180:\n",
    "            difference +=360\n",
    "        elif difference > 180:\n",
    "            difference -=360\n",
    "        diff_list.append(difference)\n",
    "    return diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_play_graph_function(data):\n",
    "    ##one_play_formatted_list = []\n",
    "    data = data.reset_index(drop=True)\n",
    "    #get y, the response variable for this play (binary pass completed or not) and possesionteam (for CV)\n",
    "    y = data[\"is_pass_failed\"][0]\n",
    "    team = data[\"possessionTeam\"][0]\n",
    "    #put play in adjacency matrix format, the distance of all players to each other (this will then be filtered to just link relevant players to QB or WR)\n",
    "    data_dist = data[[\"x\",\"y\"]]\n",
    "    adj = cdist(data_dist.values, data_dist.values)\n",
    "    for index,row in data.iterrows():\n",
    "        #connect QB to pass rush/block and wr, WR to coverage and QB, remove other connections by setting to zero\n",
    "        if (row[\"pff_role\"]==\"Coverage\" )| (row[\"pff_role\"]==\"Pass Route\"):\n",
    "            condition = ((data[\"pff_role\"]==\"Pass Block\")|(data[\"pff_role\"]==\"Pass Rush\"))\n",
    "        else:\n",
    "            condition = ((data[\"pff_role\"]==\"Coverage\"))\n",
    "        adj[index][condition] = 0\n",
    "    #then put play in features format, getting a table containing position, speed, orientation etc\n",
    "    data[\"onPossessionTeam\"] = np.where(data[\"possessionTeam\"]==data[\"team\"],1,0)\n",
    "    QB= data[data[\"pff_role\"]==\"Pass\"]\n",
    "    data[\"rel_o\"] = data[\"o\"]-QB[\"o\"].iloc[0]\n",
    "    data[\"rel_dir\"] = data[\"dir\"]-QB[\"dir\"].iloc[0]\n",
    "    data = data[[\"onPossessionTeam\",\"s\",\"rel_dir\",\"rel_o\",\"pff_role\"]]\n",
    "    one_hot = pd.get_dummies(data['pff_role'])\n",
    "    data= data.drop('pff_role',axis = 1)\n",
    "    # Join the encoded df\n",
    "    data = data.join(one_hot)\n",
    "    one_play_formatted_list = {\"team\":team,\"y\":y,\"graph_a\":adj,\"graph_x\":data}\n",
    "    return one_play_formatted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_game = tracking_players_filtered[tracking_players_filtered.gameId == 2021090900]\n",
    "one_game = one_game.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list = []\n",
    "for i in range(len(tracking_players_filtered.comb_id.unique())):\n",
    "#for i in range(10):\n",
    "    \n",
    "    one_play = tracking_players_filtered[tracking_players_filtered.comb_id==tracking_players_filtered.comb_id.unique()[i]]\n",
    "    #print(one_game.comb_id.unique()[i])\n",
    "    one_play = one_play.reset_index(drop=True)\n",
    "    result = one_play_graph_function(one_play)\n",
    "    graph_list.append(result.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'team': 'IND',\n",
       " 'y': 1,\n",
       " 'graph_a': array([[ 0.        ,  0.        ,  0.        ,  0.        , 23.70248932,\n",
       "          0.        , 17.17797718, 29.47224627,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        , 27.01342259, 17.06435466,\n",
       "          1.35915415, 23.42563553, 33.26386929],\n",
       "        [ 0.        ,  0.        ,  6.26214021,  2.8900692 ,  2.85043856,\n",
       "          2.95853004,  0.        ,  0.        ,  3.80131556,  0.86954011,\n",
       "          5.67225705,  0.80024996,  3.12712328,  0.        ,  0.        ,\n",
       "         25.96559454,  0.        ,  0.        ],\n",
       "        [ 0.        ,  6.26214021,  0.        ,  3.80595586,  3.81903129,\n",
       "          5.76042533,  0.        ,  0.        ,  6.21034621,  6.83714122,\n",
       "          0.89403579,  7.05762   ,  3.88490669,  0.        ,  0.        ,\n",
       "         21.68747334,  0.        ,  0.        ],\n",
       "        [ 0.        ,  2.8900692 ,  3.80595586,  0.        ,  2.30670761,\n",
       "          2.12268698,  0.        ,  0.        ,  2.82462387,  3.22024844,\n",
       "          3.04213741,  3.66187111,  0.39849718,  0.        ,  0.        ,\n",
       "         23.22871499,  0.        ,  0.        ],\n",
       "        [ 0.        ,  2.85043856,  3.81903129,  2.30670761,  0.        ,\n",
       "          4.10542324,  0.        ,  0.        ,  4.94418851,  3.64067301,\n",
       "          3.50235635,  3.56552941,  2.70120344,  0.        ,  0.        ,\n",
       "         24.8983875 ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  2.95853004,  5.76042533,  2.12268698,  4.10542324,\n",
       "          0.        ,  0.        ,  0.        ,  0.89269256,  2.66326867,\n",
       "          4.91495676,  3.43110769,  1.90918831,  0.        ,  0.        ,\n",
       "         23.31430891,  0.        ,  0.        ],\n",
       "        [17.17797718,  0.        ,  0.        ,  0.        , 14.5982636 ,\n",
       "          0.        ,  0.        , 12.30428381,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        , 18.02611716,  1.33180329,\n",
       "         18.52290474,  7.70156478, 16.42902614],\n",
       "        [29.47224627,  0.        ,  0.        ,  0.        , 17.52948659,\n",
       "          0.        , 12.30428381,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        , 20.51670783, 12.47006415,\n",
       "         30.82071057,  8.05546398,  6.32608094],\n",
       "        [ 0.        ,  3.80131556,  6.21034621,  2.82462387,  4.94418851,\n",
       "          0.89269256,  0.        ,  0.        ,  0.        ,  3.40618555,\n",
       "          5.33240096,  4.20409324,  2.53237043,  0.        ,  0.        ,\n",
       "         22.74876041,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.86954011,  6.83714122,  3.22024844,  3.64067301,\n",
       "          2.66326867,  0.        ,  0.        ,  3.40618555,  0.        ,\n",
       "          6.17739427,  0.81394103,  3.36630361,  0.        ,  0.        ,\n",
       "         25.93234274,  0.        ,  0.        ],\n",
       "        [ 0.        ,  5.67225705,  0.89403579,  3.04213741,  3.50235635,\n",
       "          4.91495676,  0.        ,  0.        ,  5.33240096,  6.17739427,\n",
       "          0.        ,  6.47250338,  3.07275121,  0.        ,  0.        ,\n",
       "         21.57732606,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.80024996,  7.05762   ,  3.66187111,  3.56552941,\n",
       "          3.43110769,  0.        ,  0.        ,  4.20409324,  0.81394103,\n",
       "          6.47250338,  0.        ,  3.87459675,  0.        ,  0.        ,\n",
       "         26.625223  ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  3.12712328,  3.88490669,  0.39849718,  2.70120344,\n",
       "          1.90918831,  0.        ,  0.        ,  2.53237043,  3.36630361,\n",
       "          3.07275121,  3.87459675,  0.        ,  0.        ,  0.        ,\n",
       "         22.91069619,  0.        ,  0.        ],\n",
       "        [27.01342259,  0.        ,  0.        ,  0.        , 32.29695032,\n",
       "          0.        , 18.02611716, 20.51670783,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        , 19.35611531,\n",
       "         27.91227866, 23.09864498, 18.15709228],\n",
       "        [17.06435466,  0.        ,  0.        ,  0.        , 13.30540492,\n",
       "          0.        ,  1.33180329, 12.47006415,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        , 19.35611531,  0.        ,\n",
       "         18.42016558,  7.01006419, 17.00409362],\n",
       "        [ 1.35915415,  0.        ,  0.        ,  0.        , 24.8983875 ,\n",
       "          0.        , 18.52290474, 30.82071057,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        , 27.91227866, 18.42016558,\n",
       "          0.        , 24.78122071, 34.56835692],\n",
       "        [23.42563553,  0.        ,  0.        ,  0.        , 10.15214263,\n",
       "          0.        ,  7.70156478,  8.05546398,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        , 23.09864498,  7.01006419,\n",
       "         24.78122071,  0.        , 14.11932718],\n",
       "        [33.26386929,  0.        ,  0.        ,  0.        , 23.8417491 ,\n",
       "          0.        , 16.42902614,  6.32608094,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        , 18.15709228, 17.00409362,\n",
       "         34.56835692, 14.11932718,  0.        ]]),\n",
       " 'graph_x':     onPossessionTeam     s  rel_dir   rel_o  Coverage  Pass  Pass Block  \\\n",
       " 0                  0  6.13   215.22  -25.95         1     0           0   \n",
       " 1                  1  1.65    29.90 -196.61         0     0           1   \n",
       " 2                  0  3.12    55.70 -103.64         0     0           0   \n",
       " 3                  1  1.20    52.57 -245.18         0     0           1   \n",
       " 4                  1  0.72     0.00    0.00         0     1           0   \n",
       " 5                  1  0.99   -47.24  -64.56         0     0           1   \n",
       " 6                  0  5.43   129.23 -171.37         1     0           0   \n",
       " 7                  0  6.43   265.56   20.05         1     0           0   \n",
       " 8                  0  1.66   -47.62 -262.52         0     0           0   \n",
       " 9                  1  2.69    47.23 -212.68         0     0           1   \n",
       " 10                 1  2.63    54.50 -291.97         0     0           1   \n",
       " 11                 0  3.05    30.38  -78.10         0     0           0   \n",
       " 12                 0  0.66    75.84 -276.95         0     0           0   \n",
       " 13                 0  3.84   222.54 -290.50         1     0           0   \n",
       " 14                 0  0.90    58.48 -245.10         1     0           0   \n",
       " 15                 1  6.83   214.13  -64.96         0     0           0   \n",
       " 16                 0  1.05    -2.54 -299.58         1     0           0   \n",
       " 17                 0  7.30   175.74 -101.92         1     0           0   \n",
       " \n",
       "     Pass Route  Pass Rush  \n",
       " 0            0          0  \n",
       " 1            0          0  \n",
       " 2            0          1  \n",
       " 3            0          0  \n",
       " 4            0          0  \n",
       " 5            0          0  \n",
       " 6            0          0  \n",
       " 7            0          0  \n",
       " 8            0          1  \n",
       " 9            0          0  \n",
       " 10           0          0  \n",
       " 11           0          1  \n",
       " 12           0          1  \n",
       " 13           0          0  \n",
       " 14           0          0  \n",
       " 15           1          0  \n",
       " 16           0          0  \n",
       " 17           0          0  }"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list[7000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get list of indexes of possession teams to allow masking for Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_list = []\n",
    "for i in range(len(graph_list)):\n",
    "    team_list.append(graph_list[i][\"team\"])\n",
    "unique_team_list = list(set(team_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "learning_rate = 1e-3  # Learning rate\n",
    "epochs = 100  # Number of training epochs\n",
    "es_patience = 10  # Patience for early stopping\n",
    "batch_size = 21  # Batch size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put data in graph format to feed in to GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onPossessionTeam</th>\n",
       "      <th>s</th>\n",
       "      <th>rel_dir</th>\n",
       "      <th>rel_o</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Pass</th>\n",
       "      <th>Pass Block</th>\n",
       "      <th>Pass Route</th>\n",
       "      <th>Pass Rush</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.92</td>\n",
       "      <td>30.04</td>\n",
       "      <td>201.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.64</td>\n",
       "      <td>48.99</td>\n",
       "      <td>232.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>17.26</td>\n",
       "      <td>207.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-14.55</td>\n",
       "      <td>-17.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-140.84</td>\n",
       "      <td>19.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-138.78</td>\n",
       "      <td>215.48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-68.08</td>\n",
       "      <td>-24.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>7.78</td>\n",
       "      <td>-43.93</td>\n",
       "      <td>-4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>8.19</td>\n",
       "      <td>-52.36</td>\n",
       "      <td>23.48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>-136.45</td>\n",
       "      <td>185.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>-91.83</td>\n",
       "      <td>-70.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2.38</td>\n",
       "      <td>105.01</td>\n",
       "      <td>165.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>6.04</td>\n",
       "      <td>-18.57</td>\n",
       "      <td>-91.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2.52</td>\n",
       "      <td>77.88</td>\n",
       "      <td>85.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>6.62</td>\n",
       "      <td>-197.56</td>\n",
       "      <td>199.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>14.06</td>\n",
       "      <td>157.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>52.17</td>\n",
       "      <td>189.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    onPossessionTeam     s  rel_dir   rel_o  Coverage  Pass  Pass Block  \\\n",
       "0                  1  3.83     0.00    0.00         0     1           0   \n",
       "1                  1  3.92    30.04  201.81         0     0           1   \n",
       "2                  0  3.64    48.99  232.69         0     0           0   \n",
       "3                  1  0.90    17.26  207.35         0     0           1   \n",
       "4                  0  1.23   -14.55  -17.40         0     0           0   \n",
       "5                  1  1.59  -140.84   19.14         0     0           1   \n",
       "6                  0  3.10  -138.78  215.48         1     0           0   \n",
       "7                  0  1.60   -68.08  -24.65         1     0           0   \n",
       "8                  1  7.78   -43.93   -4.97         0     0           0   \n",
       "9                  0  8.19   -52.36   23.48         1     0           0   \n",
       "10                 0  1.53  -136.45  185.62         0     0           0   \n",
       "11                 0  4.17   -91.83  -70.32         1     0           0   \n",
       "12                 1  2.38   105.01  165.74         0     0           1   \n",
       "13                 0  6.04   -18.57  -91.47         1     0           0   \n",
       "14                 1  2.52    77.88   85.46         0     0           1   \n",
       "15                 0  6.62  -197.56  199.50         1     0           0   \n",
       "16                 0  3.57    14.06  157.84         0     0           0   \n",
       "17                 0  4.44    52.17  189.75         0     0           0   \n",
       "\n",
       "    Pass Route  Pass Rush  \n",
       "0            0          0  \n",
       "1            0          0  \n",
       "2            0          1  \n",
       "3            0          0  \n",
       "4            0          1  \n",
       "5            0          0  \n",
       "6            0          0  \n",
       "7            0          0  \n",
       "8            1          0  \n",
       "9            0          0  \n",
       "10           0          1  \n",
       "11           0          0  \n",
       "12           0          0  \n",
       "13           0          0  \n",
       "14           0          0  \n",
       "15           0          0  \n",
       "16           0          1  \n",
       "17           0          1  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list[0][\"graph_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, n_samples, df, n_outcome=1, **kwargs):\n",
    "        self.n_samples = n_samples\n",
    "        self.df = df  \n",
    "        self.n_outcome = n_outcome\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        output = []\n",
    "        for i in range(self.n_samples):\n",
    "            # Node features\n",
    "            iter_x = self.df[i][\"graph_x\"].copy()\n",
    "            #print(iter_x)\n",
    "            x = np.array(iter_x)#.reshape(iter_x.shape)\n",
    "\n",
    "            # Edges\n",
    "            iter_a =  self.df[i][\"graph_a\"].copy()\n",
    "            the_length = len(iter_a)\n",
    "            a = np.array(iter_a).reshape(the_length,the_length)\n",
    "            #print(iter_a)\n",
    "            y = int(self.df[i][\"y\"])\n",
    "            \n",
    "           \n",
    "            output.append(Graph(x=x, a=a, y=y))\n",
    "        return(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train xCompletion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class xCompletion(Model):\n",
    "\n",
    "    def __init__(self, n_hidden, n_labels):\n",
    "        super().__init__()\n",
    "        self.graph_conv = GCNConv(n_hidden)\n",
    "        self.pool = GlobalSumPool()\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.dense = Dense(n_labels, 'sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        out = self.graph_conv(inputs)\n",
    "        out = self.dropout(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.dense(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop through and for each team use as val (remove from training) and store predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [i \u001b[39mfor\u001b[39;00m i, e \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(team_list) \u001b[39mif\u001b[39;00m e \u001b[39m==\u001b[39m unique_team_list[i]]\n",
      "Cell \u001b[1;32mIn[92], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [i \u001b[39mfor\u001b[39;00m i, e \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(team_list) \u001b[39mif\u001b[39;00m e \u001b[39m==\u001b[39m unique_team_list[i]]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "[j for ij, e in enumerate(team_list) if e == unique_team_list[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 38/348 [==>...........................] - ETA: 0s - loss: 49.6452 - binary_accuracy: 0.5514 "
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " ValueError: could not broadcast input array from shape (19,9) into shape (19,8)\nTraceback (most recent call last):\n\n  File \"C:\\Users\\conny\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\conny\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\conny\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 961, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\conny\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 837, in wrapped_generator\n    for data in generator_fn():\n\n  File \"c:\\Users\\conny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spektral\\data\\loaders.py\", line 99, in __next__\n    return self.collate(nxt)\n\n  File \"c:\\Users\\conny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spektral\\data\\loaders.py\", line 401, in collate\n    output = to_batch(**packed, mask=self.mask)\n\n  File \"c:\\Users\\conny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spektral\\data\\utils.py\", line 115, in to_batch\n    x_out = pad_jagged_array(x_list, (n_max, -1))\n\n  File \"c:\\Users\\conny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spektral\\utils\\misc.py\", line 25, in pad_jagged_array\n    output[slc] = x[i]\n\nValueError: could not broadcast input array from shape (19,9) into shape (19,8)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_1608]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m model \u001b[39m=\u001b[39m xCompletion(\u001b[39m200\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m model\u001b[39m.\u001b[39mcompile(\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mbinary_accuracy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m model\u001b[39m.\u001b[39;49mfit(loader_tr\u001b[39m.\u001b[39;49mload(), validation_data\u001b[39m=\u001b[39;49m loader_va\u001b[39m.\u001b[39;49mload(), steps_per_epoch\u001b[39m=\u001b[39;49mloader_tr\u001b[39m.\u001b[39;49msteps_per_epoch,\n\u001b[0;32m     24\u001b[0m validation_steps\u001b[39m=\u001b[39;49mloader_va\u001b[39m.\u001b[39;49msteps_per_epoch, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     25\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(loader_all\u001b[39m.\u001b[39mload(), steps \u001b[39m=\u001b[39mloader_all\u001b[39m.\u001b[39msteps_per_epoch)\n\u001b[0;32m     26\u001b[0m prediction_list\u001b[39m.\u001b[39mappend(predictions)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  ValueError: could not broadcast input array from shape (19,9) into shape (19,8)\nTraceback (most recent call last):\n\n  File \"C:\\Users\\conny\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\conny\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\conny\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 961, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\conny\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 837, in wrapped_generator\n    for data in generator_fn():\n\n  File \"c:\\Users\\conny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spektral\\data\\loaders.py\", line 99, in __next__\n    return self.collate(nxt)\n\n  File \"c:\\Users\\conny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spektral\\data\\loaders.py\", line 401, in collate\n    output = to_batch(**packed, mask=self.mask)\n\n  File \"c:\\Users\\conny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spektral\\data\\utils.py\", line 115, in to_batch\n    x_out = pad_jagged_array(x_list, (n_max, -1))\n\n  File \"c:\\Users\\conny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spektral\\utils\\misc.py\", line 25, in pad_jagged_array\n    output[slc] = x[i]\n\nValueError: could not broadcast input array from shape (19,9) into shape (19,8)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_1608]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "prediction_list = []\n",
    "for i in range(len(unique_team_list)):\n",
    "    team_in = [j for j, e in enumerate(team_list) if e == unique_team_list[i]]\n",
    "    team_out = [j for j, e in enumerate(team_list) if e != unique_team_list[i]]\n",
    "    training_data = [graph_list[i] for i in team_out]\n",
    "    val_data = [graph_list[i] for i in team_in]\n",
    "    all_data = graph_list\n",
    "    len_train = len(training_data)\n",
    "    len_val = len(val_data)\n",
    "    len_all = len(graph_list)\n",
    "    data_tr = GraphDataset(n_samples = len_train, df = training_data, transforms=NormalizeAdj())\n",
    "    data_va = GraphDataset(n_samples = len_val, df = val_data, transforms=NormalizeAdj())\n",
    "    data_all = GraphDataset(n_samples = len_all, df=graph_list, transforms=NormalizeAdj())\n",
    "\n",
    "# Data loaders\n",
    "    loader_tr = BatchLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
    "    loader_va = BatchLoader(data_va, batch_size=batch_size)\n",
    "    loader_all = BatchLoader(data_all, batch_size=batch_size)\n",
    "\n",
    "    model = xCompletion(200, 1)\n",
    "    model.compile('adam', \"binary_crossentropy\",\"binary_accuracy\")\n",
    "\n",
    "    model.fit(loader_tr.load(), validation_data= loader_va.load(), steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    validation_steps=loader_va.steps_per_epoch, epochs=100)\n",
    "    predictions = model.predict(loader_all.load(), steps =loader_all.steps_per_epoch)\n",
    "    prediction_list.append(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
